{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOG BOOK FOR EDAN70\n",
    "\n",
    "### Annie Tallund and Sofi Flink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200323\n",
    "\n",
    "\n",
    "**Aim**: Start up project, choose project for EDAN70.\n",
    "\n",
    "**Result**: Choose project with Sonja and Pierre as supervisors about text mining. Emailed Sonja and Pierre for information on the project and contact details.\n",
    "\n",
    "**Next step**: Read Wikipedia page about Biomedical text mining. Create journal for logging, create article template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200325\n",
    "\n",
    "**Aim**:  Read Wikipedia article provided by the supervisors. Create article template, create journal.\n",
    "\n",
    "**Result**: Read Wikipedia article, created article template.\n",
    "\n",
    "**Next step**: Meeting with supervisors for details about the project and deciding project task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200326\n",
    "\n",
    "**Aim**: Meeting with Sonja and Pierre, supervisors for this project. Deciding on a project regarding biomedical text mining.\n",
    "\n",
    "**Result**: We will be working on text mining for covid-19, specifically task 4 \"What do we know about vaccines and therapeutics?\", as described in the KAGGLE challenge \"COVID-19 Open Research Dataset Challenge\", \"CORD-19\". All groups have been divided work for the project of task 4, we will be focusing on rules for the project.\n",
    "\n",
    "**Next step**: Follow instructions in Sonja's email and complete those tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200329\n",
    "\n",
    "**Aim**: Clone the kaggle project and have a look at the data\n",
    "\n",
    "**Result**: Cloned the subset from kaggle. Experimented with the metadata.csv file and managed to filter on 'publish_time' (January 2020) just to remember how to handle csv in python, even though this was not the task\n",
    "\n",
    "**Next step**: \n",
    "Create a tagger and save in Pubannotation format according to Sonja's instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200331\n",
    "\n",
    "\n",
    "**Aim**: \n",
    "\n",
    "Sofi - Setting up environment and research for the project\n",
    "\n",
    "**Result**: \n",
    "\n",
    "Sofi - Some struggles working with imports to Jupyter, seems like the wrong environment is being executed. The goal was supposed to be to start on the project but it will be postponed until the bug is fixed with Jupyter. A work journal was also created.\n",
    "\n",
    "**Next step**: Finish setting up the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200401\n",
    "\n",
    "**Aim**: \n",
    "\n",
    "Sofi - Setting up environment and research for the project\n",
    "\n",
    "Annie - Start working on the tagger\n",
    "\n",
    "**Result**: \n",
    "\n",
    "Sofi - Environment problems in Jupyter was finally resolved. Researched Regex and NLP, text mining, data cleaning. Youtube video \"Natural Language Processing in Python\" from channel \"PyOhio\" as an introduction to NLP. Read article ”A Guide to Dictionary-Based Text Mining”\n",
    "\n",
    "Annie - Managed to get some basic functionality for the tagger working for some text from the metadata, created github repo\n",
    "\n",
    "**Next step**: Make the tagger work by loading and running it on the binary files, export it in the pubannotation format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200402\n",
    "\n",
    "**Aim**: Keep working on the tagger, attend this week's meeting\n",
    "\n",
    "**Result**: Tagger now works for the json format\n",
    "\n",
    "**Next step**: Fix the pubannotation format and prepare for the coming week's tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200403\n",
    "\n",
    "**Aim**: Read article. Start writing on the report. Learn about pubannotation, finish the pubannotiation task and test it on the webpage, start researching about regex\n",
    "\n",
    "**Result**: Read the articles and wrote an initial abstract, introduction and credits section of the report. \n",
    "\n",
    "Codewise, we've been working on some functions that will fetch and organize all information included in the format according to Sonja's guide. \n",
    "\n",
    "We also set up a notebook on kaggle. \n",
    "**Next step**: Ask Sonja if we should improve the tagger to be able to match words with spaces or focus on the next task, or maybe both (we each work on one thing). Also, dicuss how we should work with kaggle and ask about how they want the work to be submitted on kaggle?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200404\n",
    "\n",
    "**Aim**: Finish tagger-prototype, clean code and add readability in notebook on kaggle, improve on tagger\n",
    "\n",
    "**Result**: Finished a prototype for the tagger that saves correct pubannotations. Started cleaning up code one kaggle for readability but still not complete. \n",
    "\n",
    "Improvements where made but more can be done such as adding words ending in 'vir'. \n",
    "\n",
    "**Next step**: Ask Sonja about the headers for the csv-file. Ask how to handle empty entries. \n",
    "\n",
    "Improve tagger to include non-composite words and words ending in 'vir'. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200405\n",
    "\n",
    "**Aim**: clean up code and make it more readable\n",
    "\n",
    "**Result**: found som minor errors and corrected these. Did some major refactoring where we split up the code which hopefully will improve readability.\n",
    "\n",
    "**Next step**: Keep cleaning the code, start looking at the regex for detecting 'vir'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200408\n",
    "\n",
    "**Aim**: finish cleanup\n",
    "\n",
    "**Result**: We made good progress and found several points for improvement such as other variable names and transforming the metadata into a dictionary so that we don't have to keep track of the numerical index. Instead, we can now iterate through the file names.\n",
    "\n",
    "**Next step**: Catch up on the meeting and see what is prioritized at the moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200409\n",
    "\n",
    "**Aim**: Attend meeting, submit refactored code\n",
    "\n",
    "**Result**: We got some new goals and updated the TODO in our code. \n",
    "\n",
    "**Next step**: adding the 'vir' feature to the tagging and developing a greedy search so that we can find any composite words since many of the words in the dicitionaries are written apart. After that, we should construct precision and recall curves to evaluate our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200410\n",
    "\n",
    "**Aim**: Construct new subset that has correct columns and the header included \n",
    "\n",
    "**Result**: This was not part of the original plan but since we discovered a problem with the previous subset we were asked to do it. We wrote an algorithm and generated new files based on the subset. It didn't result in any matches but we tested it by adding a word that we knew would match, and it worked. Also, the code is now updated to use the header in the csv file \n",
    "\n",
    "**Next step**: Go back to the todo in our code (see above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200426\n",
    "\n",
    "**Aim**: Implement the 'vir' search with a regex expression, make tagger work for compound words\n",
    "\n",
    "**Result**: We used a simple regex expression to match each section towards each word in the dictionary. This made the program a lot slower than before, so we want to optimize the code by dynamically check for substrings in the dictionary words. Also, we implemented a regex expression to look for specific substring in a word, for example 'vir'\n",
    "\n",
    "**Next step**: Optimize and clean up code, work on evaluation for the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOG BOOK FOR EDAN70\n",
    "\n",
    "### Annie Tallund and Sofi Flink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200323\n",
    "\n",
    "\n",
    "**Aim**: Start up project, choose project for EDAN70.\n",
    "\n",
    "**Result**: Choose project with Sonja and Pierre as supervisors about text mining. Emailed Sonja and Pierre for information on the project and contact details.\n",
    "\n",
    "**Next step**: Read Wikipedia page about Biomedical text mining. Create journal for logging, create article template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200325\n",
    "\n",
    "**Aim**:  Read Wikipedia article provided by the supervisors. Create article template, create journal.\n",
    "\n",
    "**Result**: Read Wikipedia article, created article template.\n",
    "\n",
    "**Next step**: Meeting with supervisors for details about the project and deciding project task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200326\n",
    "\n",
    "**Aim**: Meeting with Sonja and Pierre, supervisors for this project. Deciding on a project regarding biomedical text mining.\n",
    "\n",
    "**Result**: We will be working on text mining for covid-19, specifically task 4 \"What do we know about vaccines and therapeutics?\", as described in the KAGGLE challenge \"COVID-19 Open Research Dataset Challenge\", \"CORD-19\". All groups have been divided work for the project of task 4, we will be focusing on rules for the project.\n",
    "\n",
    "**Next step**: Follow instructions in Sonja's email and complete those tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200329\n",
    "\n",
    "**Aim**: Clone the kaggle project and have a look at the data\n",
    "\n",
    "**Result**: Cloned the subset from kaggle. Experimented with the metadata.csv file and managed to filter on 'publish_time' (January 2020) just to remember how to handle csv in python, even though this was not the task\n",
    "\n",
    "**Next step**: \n",
    "Create a tagger and save in Pubannotation format according to Sonja's instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200331\n",
    "\n",
    "\n",
    "**Aim**: \n",
    "\n",
    "Sofi - Setting up environment and research for the project\n",
    "\n",
    "**Result**: \n",
    "\n",
    "Sofi - Some struggles working with imports to Jupyter, seems like the wrong environment is being executed. The goal was supposed to be to start on the project but it will be postponed until the bug is fixed with Jupyter. A work journal was also created.\n",
    "\n",
    "**Next step**: Finish setting up the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200401\n",
    "\n",
    "**Aim**: \n",
    "\n",
    "Sofi - Setting up environment and research for the project\n",
    "\n",
    "Annie - Start working on the tagger\n",
    "\n",
    "**Result**: \n",
    "\n",
    "Sofi - Environment problems in Jupyter was finally resolved. Researched Regex and NLP, text mining, data cleaning. Youtube video \"Natural Language Processing in Python\" from channel \"PyOhio\" as an introduction to NLP. Read article ”A Guide to Dictionary-Based Text Mining”\n",
    "\n",
    "Annie - Managed to get some basic functionality for the tagger working for some text from the metadata, created github repo\n",
    "\n",
    "**Next step**: Make the tagger work by loading and running it on the binary files, export it in the pubannotation format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200402\n",
    "\n",
    "**Aim**: Keep working on the tagger, attend this week's meeting\n",
    "\n",
    "**Result**: Tagger now works for the json format\n",
    "\n",
    "**Next step**: Fix the pubannotation format and prepare for the coming week's tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200403\n",
    "\n",
    "**Aim**: Read article. Start writing on the report. Learn about pubannotation, finish the pubannotiation task and test it on the webpage, start researching about regex\n",
    "\n",
    "**Result**: Read the articles and wrote an initial abstract, introduction and credits section of the report. \n",
    "\n",
    "Codewise, we've been working on some functions that will fetch and organize all information included in the format according to Sonja's guide. \n",
    "\n",
    "We also set up a notebook on kaggle. \n",
    "**Next step**: Ask Sonja if we should improve the tagger to be able to match words with spaces or focus on the next task, or maybe both (we each work on one thing). Also, dicuss how we should work with kaggle and ask about how they want the work to be submitted on kaggle?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200404\n",
    "\n",
    "**Aim**: Finish tagger-prototype, clean code and add readability in notebook on kaggle, improve on tagger\n",
    "\n",
    "**Result**: Finished a prototype for the tagger that saves correct pubannotations. Started cleaning up code one kaggle for readability but still not complete. \n",
    "\n",
    "Improvements where made but more can be done such as adding words ending in 'vir'. \n",
    "\n",
    "**Next step**: Ask Sonja about the headers for the csv-file. Ask how to handle empty entries. \n",
    "\n",
    "Improve tagger to include non-composite words and words ending in 'vir'. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200405\n",
    "\n",
    "**Aim**: clean up code and make it more readable\n",
    "\n",
    "**Result**: found som minor errors and corrected these. Did some major refactoring where we split up the code which hopefully will improve readability.\n",
    "\n",
    "**Next step**: Keep cleaning the code, start looking at the regex for detecting 'vir'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200408\n",
    "\n",
    "**Aim**: finish cleanup\n",
    "\n",
    "**Result**: We made good progress and found several points for improvement such as other variable names and transforming the metadata into a dictionary so that we don't have to keep track of the numerical index. Instead, we can now iterate through the file names.\n",
    "\n",
    "**Next step**: Catch up on the meeting and see what is prioritized at the moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200409\n",
    "\n",
    "**Aim**: Attend meeting, submit refactored code\n",
    "\n",
    "**Result**: We got some new goals and updated the TODO in our code. \n",
    "\n",
    "**Next step**: adding the 'vir' feature to the tagging and developing a greedy search so that we can find any composite words since many of the words in the dicitionaries are written apart. After that, we should construct precision and recall curves to evaluate our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200410\n",
    "\n",
    "**Aim**: Construct new subset that has correct columns and the header included \n",
    "\n",
    "**Result**: This was not part of the original plan but since we discovered a problem with the previous subset we were asked to do it. We wrote an algorithm and generated new files based on the subset. It didn't result in any matches but we tested it by adding a word that we knew would match, and it worked. Also, the code is now updated to use the header in the csv file \n",
    "\n",
    "**Next step**: Go back to the todo in our code (see above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200426\n",
    "\n",
    "**Aim**: Implement the 'vir' search with a regex expression, make tagger work for compound words\n",
    "\n",
    "**Result**: We used a simple regex expression to match each section towards each word in the dictionary. This made the program a lot slower than before, so we want to optimize the code by dynamically check for substrings in the dictionary words. Also, we implemented a regex expression to look for specific substring in a word, for example 'vir'\n",
    "\n",
    "**Next step**: Optimize and clean up code, work on evaluation for the program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200427\n",
    "\n",
    "**Aim**: Meeting with supervisors Sonja and Pierre with other groups on discord. Fix bug in program, no matches are found. Add tagging with variations of words in dictionary (plural form). Fix readme in order to aid others using the tagger setting up environment. Clean up code. Fix a notebook version for code. Prioritize longest match between classes 'Virus_SARS-CoV-2' and 'Disease_COVID-19'\n",
    "\n",
    "**Result**: Feedback from supervisors where: Developing the evaluation platform with other dictionary group so we can compare results of the implementation. Bug was fixed, it was only a wrong check making empty text strings enter the tagging methods. Tagging of plural version of words where implemented with optional variations of words ending in 's' and 'es' but only for vocabulary words. Readme was created with steps in order to install necessary library. Priority system implemented as well. Notebook guide created with implementation.\n",
    "\n",
    "**Next step**: Evaluation of implementation using Golden Standard from Aitslab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200430\n",
    "\n",
    "**Aim**: Create an evaluator class for pubannotations using gold and silerstandard.\n",
    "\n",
    "**Result**: Created a prototype evaluator class for pubannotations, only based on the span.\n",
    "\n",
    "**Next step**: Implement it so that it also takes the class into account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200503\n",
    "\n",
    "\n",
    "**Aim**: Finish the prototype for evaluation \n",
    "\n",
    "**Result**: Created a prototype evaluator class for pubannotations, not tested for gold and silverstandard yet.\n",
    "\n",
    "**Next step**: Try the evaluator class with gold and silverstandard. Write in the report and add the evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200505\n",
    "\n",
    "\n",
    "**Aim**: Meeting with supervisors and project members. Finish evaluation with gold standard test. \n",
    "\n",
    "**Result**: Met with supervisors, we are supposed to add result for macro and micro for precision and recall. This was implemented after the meeting. The gold standard subset test generated by Salma does not contain the same format as the Kaggle input data. We manually edited the output files and input file to match the kaggle input data and pubannotations format, but did not finish. Talked to Jesper and he have worked around it instead, but we wish to test our tagger without changing it since it might sneak in some errors otherwise. The layout of folders where changed in the project in order to make it easier to find files in the project. The project is now split with a bin folder containing the main program which is calling the classes in 'src' folder where the classes DictionaryTagger, PubannotationGenerator and PubannotationEvaluator where.\n",
    "\n",
    "**Next step**: Try the evaluator class with gold standard. Write in the report and add the evaluation. Work through small task list of generating docs for classes, update readme, code clean up, finish reformatting test gold standard output and input. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200506\n",
    "\n",
    "\n",
    "**Aim**: Write about implementation in report, evaluate dictionaries and tagger with golden standard.\n",
    "\n",
    "**Result**: Wrote about our implementation shortly in the report, created docs for classes and fixed some issues with the code.\n",
    "\n",
    "**Next step**: Try the evaluator class with gold standard, try dictionary groups evaluator on our tagger output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200506\n",
    "\n",
    "\n",
    "**Aim**: Evaluate dictionaries and tagger with golden standard using our and dictionary groups evaluator.\n",
    "\n",
    "**Result**: Progress prints where implemented in order to aid the user when running the code. Evaluation done on our tagger, shared result with other project members. Some words tagged in gold standard output does not exist in the vocabularies. Could not interpret result and have asked Jesper and Jenny for help. Waiting for answer before continuing on the report. Code clean up.\n",
    "\n",
    "**Next step**: Wait for response, write report, update readme with instructions for others using the implementation, implement function for calculating harmonic means figure and print result, list all errors (mismatches) from evaluation (false negatives and false positives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200507\n",
    "\n",
    "\n",
    "**Aim**: Write report, update readme, implement function for calculating harmonic means.\n",
    "\n",
    "**Result**: Wrote on report about implementation, compared result with dictionary group. It differs but it seems like the dictionary groups is missing some tags after going through the outputs manually, small bug fixes to code. Harmonic means calculation and representation impelemented.\n",
    "\n",
    "**Next step**: List all errors (mismatches) from evaluation (false negatives and false positives). Progress bar for code, indentations for output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200508\n",
    "\n",
    "\n",
    "**Aim**: Write report, code clean up, list errors from manually going through our output compared to gold standard output. Progress bar, indentations for pubannotations.\n",
    "\n",
    "**Result**: Wrote a bit more on report, read some old reports from other students in course, listed half of the output errors from golden standard evaluation test, implemented a progress bar, fixed indentations for pubannotations output. Fixed support for hyphens for dictionary words.\n",
    "\n",
    "**Next step**: Write on report, send output to Anton for BioBert training, work on presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200509\n",
    "\n",
    "\n",
    "**Aim**: Finish list on manual match comparison between gold standard and tagger output. Fix bugs found from list, send final output to anton for biobert training, generate table with evaluation results and push to repository,  code clean up.\n",
    "\n",
    "**Result**: Finished list of pubannotations matches, fixed bugs like double tagged annotations and missed matches, generated and sent final output to anton for biobert training, generated and pushed a table of result to repository, cleaned up in code.\n",
    "\n",
    "**Next step**: Write on report, prepare presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200510\n",
    "\n",
    "**Aim**: Finish report and presentation. \n",
    "\n",
    "**Result**: We made progress on the report and presentation\n",
    "\n",
    "**Next step**: Meeting tomorrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20201511\n",
    "\n",
    "**Aim**: Meeting, ask about report, wrap things up\n",
    "\n",
    "**Result**: We occured an unexpected issue with the evaluation: since the file names are different in the gold standard and the tagger output, there is no way to connect the two unique entities. This lead to abstract denotations being compared with title denotations, which of course led to a misleadning result. We decided to rename the files, since this is the more consistent solution, which also assumes that the formatting guidelines for the projects are followed. After that, the evaluation showed a much better result of the tagger, which also correlates better to the manual checks we did for the matches.\n",
    "\n",
    "Also, we worked on a more consistent way to handle our imports since this has been a minor issue when coding on different machines in different environments. \n",
    "\n",
    "**Next step**: Update all figures with the new results and rewrite some parts in the report with respect to these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200512\n",
    "\n",
    "**Aim**: Another issue occured as another group got true positives for classes that were not annotated in the tagger. Also, we get the wrong amount of false positives. The aim is to solve these bugs.\n",
    "\n",
    "**Result**: Used the debugger in PyCharm to identify what was wrong. The second problem was as simple as updating the dictionaries 'is_checked' so that each denotation gets their own, and adjusting the intendent of the update. Secondly, we worked out a solution for the true positives. If a phrase is matched with the same span but in different dictionaries, this will slip through as a true positive. Therefore, we added a check that grants the classes to match, too. Also, we finished the slides and sent them to Sonja for feedback. \n",
    "\n",
    "**Next step**: Write report, update figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200513\n",
    "\n",
    "**Aim**: Update the report according to our new figures\n",
    "\n",
    "**Result**: We updated the code and adjusted the check from yesterday, which was discovered by another group. Also, we wrote the report and uploaded the new version of the evaluator to prototypes repo, and updated the figures in bionlp/evaluation. \n",
    "\n",
    "**Next step**: Get feedback on report and slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
